# QueryMate ğŸ¤–

A modern, powerful AI chat application that lets you interact with multiple AI providers in one place. Built with Next.js 15, featuring real-time streaming responses, voice input, file attachments, and a beautiful mobile-responsive UI.

![QueryMate UI](public/Querymate_UI.png)

## âœ¨ Key Features

### ğŸ¯ Multi-AI Provider Support (10+ Models)

- **Google Gemini**: Gemini 2.5 Flash & Flash Lite - Fast and intelligent with web search
- **Perplexity AI**: Sonar & Sonar Pro - Real-time web search with citations
- **Groq**: Lightning-fast inference with Llama 3.3 70B, Llama 3.1 8B, Llama 4 Scout, Llama 4 Maverick, Qwen 3 32B, and Kimi K2
- Switch between AI models seamlessly within conversations

### ğŸ’¬ Advanced Chat Features

- Real-time streaming responses with elegant typing indicators
- **ğŸ¤ Voice Input**: Speech-to-text for hands-free messaging
- **ğŸ“ File Attachments**: Upload images and PDFs (Gemini & Perplexity)
- **ğŸ” Web Search Toggle**: Enable/disable web search for Gemini models
- Markdown support with syntax-highlighted code blocks
- Conversation history with persistent storage
- Auto-generated conversation titles using AI

### ğŸ” Secure Authentication

- Email/Password authentication
- OAuth support (Google & GitHub)
- JWT token-based session management
- Protected API routes with Bearer authentication

### ğŸ¨ Modern UI/UX

- **Claude-style sidebar** with QueryMate branding
- Beautiful dark/light mode support
- **Fully mobile-responsive design**
- Collapsible user profile section
- Toast notifications for all actions
- Loading states and error handling

### ğŸ“± Conversation Management

- Create unlimited conversations
- Update conversation titles
- Delete conversations with cascade message deletion
- **ğŸ“¤ Export all conversations** (JSON format)
- **ğŸ“¥ Import conversations** from backup
- **ğŸ“„ Export to PDF** per conversation
- **ğŸ“Š Analytics Dashboard** with usage statistics
- Search/filter conversations

## ğŸš€ Tech Stack

- **Framework**: Next.js 15 (App Router)
- **Language**: TypeScript
- **Database**: PostgreSQL (Supabase)
- **ORM**: Drizzle ORM
- **Authentication**: Better Auth
- **AI Providers**:
  - Google Gemini (via @ai-sdk/google)
  - Perplexity AI (via @ai-sdk/perplexity)
  - Groq (via @ai-sdk/groq)
- **AI SDK**: Vercel AI SDK
- **UI Components**: Radix UI, Shadcn/ui
- **Styling**: Tailwind CSS
- **Markdown**: react-markdown with Shiki syntax highlighting
- **PDF Export**: jsPDF
- **Data Fetching**: SWR

## ğŸ¯ What Makes QueryMate Special?

1. **10+ AI Models in One Place**: Switch between Google Gemini, Perplexity, and Groq models instantly
2. **Real-time Streaming**: See AI responses as they're generated
3. **Voice Input**: Speak your messages with built-in speech recognition
4. **File Support**: Upload images and PDFs for AI analysis
5. **Export Everything**: JSON export, PDF export, and import functionality
6. **Mobile-First Design**: Fully responsive with optimized mobile layouts
7. **Type-Safe**: Built with TypeScript for reliable code

## ğŸ› ï¸ Installation

### Prerequisites

- Node.js 20+ installed
- PostgreSQL database (Supabase account recommended)
- Google AI API key
- (Optional) GitHub & Google OAuth credentials

### Setup Steps

1. **Clone the repository**

```bash
git clone https://github.com/Jaswanth1406/QueryMate.git
cd QueryMate/querymate
```

2. **Install dependencies**

```bash
npm install
```

3. **Configure environment variables**

Create `.env.local` file in the project root:

```env
# --- SUPABASE ---
SUPABASE_DB_URL=your_supabase_db_url
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# --- BETTER AUTH ---
BETTER_AUTH_SECRET=your_secret_key_min_32_chars
BETTER_AUTH_URL=http://localhost:3000

# --- GOOGLE OAUTH ---
GOOGLE_CLIENT_ID=your_google_client_id
GOOGLE_CLIENT_SECRET=your_google_client_secret

# --- GITHUB OAUTH ---
GITHUB_CLIENT_ID=your_github_client_id
GITHUB_CLIENT_SECRET=your_github_client_secret

# --- GOOGLE GEMINI ---
GOOGLE_GENERATIVE_AI_API_KEY=your_google_ai_api_key

# --- PERPLEXITY AI ---
PERPLEXITY_API_KEY=your_perplexity_api_key

# --- GROQ ---
GROQ_API_KEY=your_groq_api_key
```

4. **Push database schema**

```bash
npx drizzle-kit push
```

5. **Run development server**

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to view the app.

## ğŸ“š API Documentation

### Authentication Endpoints

#### Sign Up

```http
POST /api/auth/sign-up/email
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "securePassword123",
  "name": "John Doe"
}
```

**Response:**

```json
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "user": {
    "id": "user_123",
    "email": "user@example.com",
    "name": "John Doe"
  }
}
```

#### Sign In

```http
POST /api/auth/sign-in/email
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "securePassword123"
}
```

**Response:**

```json
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "user": {
    "id": "user_123",
    "email": "user@example.com",
    "name": "John Doe"
  }
}
```

#### Get Current Session

```http
GET /api/auth/sessions
Authorization: Bearer YOUR_TOKEN_HERE
```

**Response:**

```json
{
  "user": {
    "id": "user_123",
    "email": "user@example.com",
    "name": "John Doe"
  },
  "session": {
    "id": "session_456",
    "expiresAt": "2025-12-25T00:00:00.000Z"
  }
}
```

#### Sign Out

```http
POST /api/auth/sign-out
Authorization: Bearer YOUR_TOKEN_HERE
Content-Type: application/json
```

**Response:**

```json
{
  "success": true
}
```

### Conversation Endpoints

#### Create New Conversation

```http
POST /api/conversations
Authorization: Bearer YOUR_TOKEN_HERE
Content-Type: application/json

{
  "title": "My Chat About AI"
}
```

**Response:**

```json
{
  "conversation": {
    "id": "conv_789",
    "userId": "user_123",
    "title": "My Chat About AI",
    "createdAt": "2025-11-25T10:00:00.000Z"
  }
}
```

#### Get All Conversations

```http
GET /api/conversations
Authorization: Bearer YOUR_TOKEN_HERE
```

**Response:**

```json
{
  "conversations": [
    {
      "id": "conv_789",
      "userId": "user_123",
      "title": "My Chat About AI",
      "createdAt": "2025-11-25T10:00:00.000Z",
      "updatedAt": "2025-11-25T10:00:00.000Z"
    }
  ]
}
```

#### Update Conversation Title

```http
PUT /api/conversations
Authorization: Bearer YOUR_TOKEN_HERE
Content-Type: application/json

{
  "id": "conv_789",
  "title": "Updated Title"
}
```

**Response:**

```json
{
  "conversation": {
    "id": "conv_789",
    "userId": "user_123",
    "title": "Updated Title",
    "createdAt": "2025-11-25T10:00:00.000Z",
    "updatedAt": "2025-11-25T10:30:00.000Z"
  }
}
```

#### Delete Conversation

```http
DELETE /api/conversations
Authorization: Bearer YOUR_TOKEN_HERE
Content-Type: application/json

{
  "id": "conv_789"
}
```

**Response:**

```json
{
  "message": "Conversation & messages deleted"
}
```

> **Note**: Deleting a conversation will also delete all associated messages. This action cannot be undone.

### Message Endpoints

#### Get Messages for a Conversation

```http
GET /api/messages?conversationId=conv_789
Authorization: Bearer YOUR_TOKEN_HERE
```

**Response:**

```json
{
  "messages": [
    {
      "id": "msg_001",
      "conversationId": "conv_789",
      "role": "user",
      "content": "Hello, what is AI?",
      "createdAt": "2025-11-25T10:00:00.000Z"
    },
    {
      "id": "msg_002",
      "conversationId": "conv_789",
      "role": "assistant",
      "content": "AI stands for Artificial Intelligence...",
      "createdAt": "2025-11-25T10:00:05.000Z"
    }
  ]
}
```

### Chat Endpoint

#### Send Message & Get AI Response

```http
POST /api/chat
Authorization: Bearer YOUR_TOKEN_HERE
Content-Type: application/json

{
  "message": "What is machine learning?",
  "conversationId": "conv_789",
  "model": "gemini-2.5-flash",
  "useSearch": true
}
```

**Parameters:**

- `message` (required): The user's message text
- `model` (required): AI model ID (see table below)
- `conversationId` (optional): ID of existing conversation
- `useSearch` (optional): Enable web search for Gemini models

**Available Models:**

| Provider   | Model ID                | Description                |
| ---------- | ----------------------- | -------------------------- |
| Google     | `gemini-2.5-flash`      | Fast and efficient         |
| Google     | `gemini-2.5-flash-lite` | Ultra fast, cost-efficient |
| Perplexity | `sonar`                 | Web-connected AI search    |
| Perplexity | `sonar-pro`             | Advanced web-connected AI  |
| Groq       | `llama-3.3-70b`         | Versatile large model      |
| Groq       | `llama-3.1-8b`          | Fast instant responses     |
| Groq       | `llama-4-scout`         | Latest Llama 4 model       |
| Groq       | `llama-4-maverick`      | Extended context Llama 4   |
| Groq       | `qwen3-32b`             | Alibaba's Qwen model       |
| Groq       | `kimi-k2`               | Moonshot AI model          |

**Response:** Streaming text response from AI (Server-Sent Events)

## ğŸ”‘ Key Concepts

### Multi-AI Architecture

QueryMate supports three AI providers with 10+ models:

1. **Google Gemini**
   - Fast, general-purpose AI with web search
   - Supports file uploads (images, PDFs)
   - Token usage tracking
   - Models: `gemini-2.5-flash`, `gemini-2.5-flash-lite`

2. **Perplexity AI**
   - Real-time web search with citations
   - Supports file uploads
   - Models: `sonar`, `sonar-pro`

3. **Groq**
   - Lightning-fast inference (fastest in the world!)
   - Multiple open-source models
   - Models: `llama-3.3-70b`, `llama-3.1-8b`, `llama-4-scout`, `llama-4-maverick`, `qwen3-32b`, `kimi-k2`

### Voice Input

- Click the microphone button to start voice input
- Speech is transcribed in real-time
- Works on Chrome, Edge, and Safari

### File Attachments

- Click the + button â†’ "Add File"
- Supported: Images (JPEG, PNG, GIF, WebP), PDFs
- Works with Gemini and Perplexity models
- Groq models do not support attachments

### Export/Import Features

- **Export All**: Download all conversations as JSON backup
- **Import**: Restore conversations from JSON backup
- **PDF Export**: Export individual chats as formatted PDFs

### Conversation vs Chat

- **Conversation**: A container/thread that holds multiple messages (like a WhatsApp chat)
- **Chat**: The action of sending/receiving messages within a conversation
- You can start chatting without explicitly creating a conversation - the `/api/chat` endpoint auto-creates one!
- Each conversation maintains its own history and context

### Authentication Flow

1. User signs up/signs in â†’ Receives JWT token
2. Store token in localStorage/cookies/state
3. Include token in `Authorization: Bearer {token}` header for all API requests
4. Backend validates token and extracts user session

### Message Flow

1. **New Chat**: POST to `/api/chat` with `message` + `model` â†’ Backend creates conversation â†’ Returns AI response
2. **Continue Chat**: POST to `/api/chat` with `conversationId` + `message` + `model` â†’ AI responds with full conversation context
3. **Load History**: GET `/api/messages?conversationId={id}` â†’ Returns all messages in conversation
4. **Switch Models**: Change `model` parameter mid-conversation to get responses from different AI providers

### Streaming Responses

All AI responses use Server-Sent Events (SSE) for real-time streaming:

- Responses appear word-by-word as they're generated
- Better user experience with immediate feedback
- More efficient than waiting for complete responses

## ï¿½ API Rate Limits

| Provider   | Model                 | RPM         | RPD   | TPM  |
| ---------- | --------------------- | ----------- | ----- | ---- |
| Google     | Gemini 2.5 Flash      | 5           | 20    | 250K |
| Google     | Gemini 2.5 Flash Lite | 10          | 20    | 250K |
| Groq       | Llama 3.3 70B         | 30          | 1000  | 12K  |
| Groq       | Llama 3.1 8B          | 30          | 14400 | 6K   |
| Groq       | Llama 4 Scout         | 30          | 1000  | 30K  |
| Groq       | Qwen 3 32B            | 60          | 1000  | 6K   |
| Perplexity | Sonar/Pro             | Pay-per-use | -     | -    |

## ï¿½ğŸ—‚ï¸ Database Schema

```
user
â”œâ”€â”€ id (text, primary key)
â”œâ”€â”€ name (text)
â”œâ”€â”€ email (text, unique)
â”œâ”€â”€ emailVerified (boolean)
â””â”€â”€ timestamps
1. **Sign Up**: POST to `/api/auth/sign-up/email` â†’ Save token
2. **Get Session**: GET `/api/auth/sessions` with Bearer token
3. **Create Conversation**: POST to `/api/conversations` with Bearer token
4. **Send Message**: POST to `/api/chat` with Bearer token and message
5. **Load Messages**: GET `/api/messages?conversationId=...` with Bearer token
6. **Sign Out**: POST to `/api/auth/sign-out` with Bearer token
â”œâ”€â”€ expiresAt (timestamp)
â””â”€â”€ metadata (ipAddress, userAgent)

conversations
â”œâ”€â”€ id (text, primary key)
â”œâ”€â”€ userId (text, foreign key â†’ user.id)
â”œâ”€â”€ title (text)
â””â”€â”€ timestamps

messages
â”œâ”€â”€ id (text, primary key)
â”œâ”€â”€ conversationId (text, foreign key â†’ conversations.id)
â”œâ”€â”€ role (text: 'user' | 'assistant')
â”œâ”€â”€ content (text)
â””â”€â”€ createdAt (timestamp)
```

## ğŸ§ª Testing with Postman

### Quick Testing Flow

1. **Sign Up**:

   ```
   POST /api/auth/sign-up/email
   Body: { "email": "test@example.com", "password": "password123", "name": "Test User" }
   ```

   â†’ Copy the `token` from response

2. **Get Session** (Verify authentication):

   ```
   GET /api/auth/sessions
   Headers: Authorization: Bearer {your_token}
   ```

3. **Start New Chat with Gemini**:

   ```
   POST /api/chat
   Headers: Authorization: Bearer {your_token}
   Body: { "message": "Hello! Tell me about AI", "model": "gemini" }
   ```

4. **Try Different AI Model**:

   ```
   POST /api/chat
   Headers: Authorization: Bearer {your_token}
   Body: { "message": "What's the latest tech news?", "model": "perplexity" }
   ```

5. **Load Conversations**:

   ```
   GET /api/conversations
   Headers: Authorization: Bearer {your_token}
   ```

6. **Get Message History**:

   ```
   GET /api/messages?conversationId={conversation_id}
   Headers: Authorization: Bearer {your_token}
   ```

7. **Sign Out**:

   ```
   POST /api/auth/sign-out
   Headers: Authorization: Bearer {your_token}
   ```

> **Note**: The `/api/chat` endpoint returns streaming responses. In Postman you'll see 200 status, but the response streams over time. Check your database `messages` table to verify AI responses are saved correctly.

## ğŸš€ Deployment

### Environment Variables for Production

**Required:**

- `SUPABASE_DB_URL`: PostgreSQL connection string
- `BETTER_AUTH_SECRET`: Secure random string (min 32 chars)
- `BETTER_AUTH_URL`: Your production domain

**AI Providers (at least one):**

- `GOOGLE_GENERATIVE_AI_API_KEY`: For Gemini
- `PERPLEXITY_API_KEY`: For Perplexity
- `GROQ_API_KEY`: For Groq

**Optional (OAuth):**

- `GOOGLE_CLIENT_ID` & `GOOGLE_CLIENT_SECRET`
- `GITHUB_CLIENT_ID` & `GITHUB_CLIENT_SECRET`

### Deploy on Vercel

1. Fork/Clone the repository
2. Import to Vercel, add environment variables
3. Deploy!
4. Run `npx drizzle-kit push` for database

## ğŸ¯ Use Cases

- **Developers**: Get coding help, compare AI responses
- **Researchers**: Real-time web search with Perplexity citations
- **Students**: Learn from multiple AI perspectives
- **Writers**: Generate content with different models
- **Everyone**: Fast answers with Groq's lightning inference

## ğŸŒŸ Roadmap

- [x] Voice input support
- [x] File upload and analysis
- [x] Export conversations to PDF
- [x] Export/Import conversations (JSON)
- [x] Analytics dashboard
- [x] Mobile-responsive design
- [x] Groq integration (10+ models)
- [ ] Shared conversations with public links
- [ ] Custom AI parameters (temperature, max tokens)
- [ ] Team workspaces
- [ ] Plugin system

## ğŸ“ License

MIT License - feel free to use this project for personal or commercial purposes.

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. ğŸ› **Report Bugs**: Open an issue with details
2. ğŸ’¡ **Suggest Features**: Share your ideas in discussions
3. ğŸ”§ **Submit PRs**: Fix bugs or add features
4. ğŸ“– **Improve Docs**: Help make documentation clearer

### Development Setup for Contributors

```bash
git clone https://github.com/Jaswanth1406/QueryMate.git
npm install
cp .env.example .env.local  # Add your API keys
npx drizzle-kit push
npm run dev
```

## ğŸ“§ Support & Contact

- **GitHub**: [@Jaswanth1406](https://github.com/Jaswanth1406)
- **Issues**: [Report bugs or request features](https://github.com/Jaswanth1406/QueryMate/issues)

## ğŸ™ Acknowledgments

- [Vercel AI SDK](https://sdk.vercel.ai) for seamless AI integration
- [Better Auth](https://better-auth.com) for robust authentication
- [Drizzle ORM](https://orm.drizzle.team) for type-safe database queries
- [Radix UI](https://radix-ui.com) & [Shadcn/ui](https://ui.shadcn.com) for components
- [Tailwind CSS](https://tailwindcss.com) for styling
- [jsPDF](https://github.com/parallax/jsPDF) for PDF generation
- [Shiki](https://shiki.style) for syntax highlighting

---

<div align="center">

**Built with â¤ï¸ by [Jaswanth1406](https://github.com/Jaswanth1406)**

If you find this project helpful, please â­ star the repository!

[Demo](https://querymate.vercel.app) Â· [Documentation](https://github.com/Jaswanth1406/QueryMate#readme) Â· [Report Bug](https://github.com/Jaswanth1406/QueryMate/issues)

</div>
